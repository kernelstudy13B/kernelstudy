# 170303 Kernel Study
## 작성자 : 김영우, koain@naver.com

### 함수 : sched_init -> init_idle -> kasan_unpoison_task_stack(struct task_struct *task)
#### Kernel Address Sanitizer (KASAN)

* KASAN is a dynamic memory error detector. It provides a fast and comprehensive solution for finding use-after-free and out-of-bounds bug.

* 메모리 에러 감별해내는 기능을 한다. 컴파일 타임에 모든 메모리 접근에 대해서 스택 또는 전역 변수들에 대한 out-of-bounds access에 대한 탐지를 해낸다. 아래 문제들을 검사한다.
  1. Buffer Overflow in heap, stack and globals.
  2. heap-use-after-free : 접근해서는 안되는 힙에 접근하는 경우 발생하는 버그. (예. 동적할당된 후 프리한 공간에 대해서 다시 참조하게 되는 경우)

  3. stack-use-after-return

* shadow : 메모리가 유효한지 나타내는 테이블. 8bytes 주소에 대해서 각 주소가 유효한지 1byte로 나타낸다. 0이면 8bytes 모두가 유효하고, 1~7이면, 8bytes 주소의 앞부터 숫자 만큼의 bytes가 유효함을 나타낸다. (shadow 값이 2라면, 8bytes중 앞 2bytes가 유효하고 뒤의 6bytes는 유효하지 않다.)

* Poison : 특정 메모리 공간에 magic value를 넣어서 유효한지 확인

* Unpoison : magic value를 지워버림(0으로 채움)

```C
 55 void kasan_unpoison_shadow(const void *address, size_t size)
 56 {
 57         kasan_poison_shadow(address, size, 0);
 58
 59         if (size & KASAN_SHADOW_MASK) {
 60                 u8 *shadow = (u8 *)kasan_mem_to_shadow(address + size);
 61                 *shadow = size & KASAN_SHADOW_MASK;
 62         }
 63 }
/*
57 : address ~ address + size 만큼에 대한 shadow를 0으로 만듬
59 : 8바이트 단위로 shadow값을 정하기 때문에 마지막 8바이트는 align 되어 있지 않을 수 있기 때문에 이에 대해 체크한다.
60 : address+size에 대한 shadow값이 저장된 주소를 가져온다.
61 : address+size ~ address+size+8 의 범위내에서 유효한 byte 개수를 shadow에 저장한다.
예) address가 8byte로 떨어지고 size가 68 바이트라면 addr ~ addr+72 의 주소에 대한 shadow가 모두 0으로 되어 있다.
하지만, 실제 유효한 size는 68이기 때문에 addr+69 ~ addr+72에 대한 메모리 접근은 유효하지 않다.
그렇기에 addr+68에 대한 shadow 값은 4로 설정된다.
*/
```

<https://kernel.org/doc/html/latest/dev-tools/kasan.html>
<http://events.linuxfoundation.org/sites/events/files/slides/LinuxCon%20North%20America%202015%20KernelAddressSanitizer.pdf>

---
### 함수 : sched_init -> init_idle -> void set_cpus_allowed_common(struct task_struct *p, const struct cpumask *new_mask)
#### struct task_struct->cpus_allowed, nr_cpus_allowed

* cpus_allowed : 태스크의 CPU affinity 정보를 저장하는 멤버 변수 (어떤 CPU에 친화력이 있는가를 비트로 나타내는것 같은데... 불확실)

* nr_cpus_allowed : cpus_allowed에 지정된 CPU의 개수가 아닐지... (cpus_allowed에 설정된 bit수를 세서 지정하던데...)

<https://kernel.org/pub/linux/kernel/people/rml/cpu-affinity/README-cpu-affinity>

---
### 함수 : sched_init -> init_idle -> static inline void __set_task_cpu(struct task_struct *p, unsigned int cpu)

#### CFS

* 각 태스크들에게 동일한 vruntime이 할당되고, vruntime에 도달한 태스크는 태스크 스위칭이 일어나게 된다.(보통 vruntime이 아닌 real time slice를 계산해 스케줄링이 결정된다.)

* 각 프로세스의 vruntime은 고정되지만 real time slice는 각 프로세스의 priority에 따라 다른 값을 갖는다.

* 실행 주기(시간 단위)란 런큐의 모든 태스크가 한번씩은 실행되어야 하는 시간이다. 즉 런큐에 존재하는 태스크들은 이 실행 주기를 나눠 써야하며 그 것을 real time slice라고 한다.

* real time slice는 다음과 같은 공식에 의해 프로세스들에게 분배 된다.
> 런큐의 Task_n의 real time slice = 실행 주기 \* (Task_n의 우선순위(가중치) / 모든 Task의 우선순위(가중치)의 합)

* 모든 태스크의 vruntime을 비슷하게 맞춰준다해서 CFS라 불린다.
> vruntime
= real time slice \* (nice 0의 가중치(1024) / Task_n의 우선순위(가중치))
= 실행 주기 \* (nice 0의 가중치(1024) / 모든 Task의 우선순위(가중치) 의 합

* 우선순위가 높은 태스크의 경우 vruntime 증가값을 작게 시간이 느리게 가는 것처럼(더 오래 실행되도록) 우선순위가 낮은 태스크의 경우 vruntime 증가값을 크게해 시간이 빨리 가는 것처럼(더 짧은 시간동안 CPU를 이용하도록) 한다.

* 결과적으로 한 실행 주기내에서 태스크들은 real time slice만큼 수행되고 vruntime은 비슷하게 증가되게 된다.

<http://nzcv.egloos.com/6014171>
<http://iloveriver.egloos.com/6095529>

#### task_group

* CFS(Completely Fair Scheduler)에서 특정 그룹의 태스크가 자원을 많이 할당받는 상황을 해결하기 위해 도입한 개념 ex) 철수가 99개 프로세스 영희가 1개 프로세스 철수가 99만큼 쓰고 영희가 1개만 쓰면 불공평

* 프로세스를 그룹짓는 기준은 "사용자 ID” 기반과 "cgroup 가상 파일 시스템" 기반이 있다.

* 사용자 ID : 특정 사용자 별로 태스크를 그룹화해 cpu 자원을 공평하게 배분

* cgroup 가상파일시스템 : 사용자가 지정한 태스크들을 하나의 그룹으로 취급해 공평하게 cpu 자원을 배분

#### sched_entity
* 커널의 스케줄링 단위이다. task_group도 하나의 sched_entity로 표현 가능. task_struct나 task_group구조체에 sched_entity를 포함 시킴으로써 그룹화해서 스케줄링이 가능하게 함.

* 각 CPU별로 run queue(rb tree)를 갖는다. sched_entity가 속하는 rq가 cfs_rq, 자신이 소유한 rq가 my_q.

<https://iamyooon1.gitbooks.io/linux-kernel-core-with-vanilla/content/d0dc_c2a4_d06c_adf8_b8f9_acfc_sched_entity_,_cfs_r.html>
<http://www.kandroid.org/board/data/board/conference/file_in_body/1/211th_kandroidconf_sched.pdf>

#### Priority Inheritance

* struct task_struct->pi_lock의 의미는 pi_data에 대한 lock을 의미

---
